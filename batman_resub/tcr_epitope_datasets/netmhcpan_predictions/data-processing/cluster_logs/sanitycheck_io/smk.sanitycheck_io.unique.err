Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 96
Rules claiming more threads will be scaled down.
Provided resources: mem_mb=1000, mem_mib=954, disk_mb=1000, disk_mib=954
Select jobs to execute...

[Sun Sep 15 14:57:28 2024]
rule sanitycheck_io:
    input: data/netmhcpan_inputs_mhc_i.csv, data/predictions/netMHCpan_formated.csv
    output: data/sanitycheck_peptides_predictions.txt
    jobid: 0
    reason: Missing output files: data/sanitycheck_peptides_predictions.txt
    resources: mem_mb=1000, mem_mib=954, disk_mb=1000, disk_mib=954, tmpdir=/tmp/8893538.1.comp.q


        pep=`wc -l data/predictions/netMHCpan_formated.csv`
        pred=`wc -l data/netmhcpan_inputs_mhc_i.csv`
        echo "$pep	$pred" >> data/sanitycheck_peptides_predictions.txt.tmp
        awk  '{ print $3, $1, $2, ($2-1) - ($1-1)*2}' data/sanitycheck_peptides_predictions.txt.tmp > data/sanitycheck_peptides_predictions.txt
        rm data/sanitycheck_peptides_predictions.txt.tmp
        
[Sun Sep 15 14:57:28 2024]
Finished job 0.
1 of 1 steps (100%) done
